{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from PIL import Image as PILImage\n",
    "from Prompts import *\n",
    "import pickle as pkl\n",
    "import yaml\n",
    "from utils.config import *\n",
    "from utils.models import *\n",
    "import copy\n",
    "import subprocess\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(config = dict(\n",
    "    MODEL_NAME = MODEL\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('locations',LOCATION,'scene_graph.json'),'r') as f:\n",
    "    scene_graph = json.load(f)\n",
    "scgraph = utils.SceneGraph(scene_graph)\n",
    "encoded_img = utils.encode_image(os.path.join('locations',LOCATION,'scene_graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('11', '07', 'f7', 'd9', 'aa', '69', 'cf', '0e', '32', 'cb', 'ba', '99', 'e3', 'f5', '48', '47', 'c5', '79'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scgraph.graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('11','07') in scgraph.graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AISLE', 'CORNER', 'INTERSECTION', 'OPEN AREA']\n"
     ]
    }
   ],
   "source": [
    "node_types = []\n",
    "for node in scgraph.get_parent_nodes():\n",
    "    if scgraph.graph.nodes[node]['type'] not in node_types:\n",
    "        node_types.append(scgraph.graph.nodes[node]['type'])\n",
    "print(node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = [{\"role\": \"system\", \n",
    "     \"content\": [{\n",
    "         \"type\":\"text\",\n",
    "         \"text\":f\"\"\"\n",
    "        You are an expert floor planner and a software engineer. You ALWAYS provide output that in JSON which is fully parseable with json.dumps in python.\n",
    "         \"\"\"}]\n",
    "     },\n",
    "{\"role\": \"user\", \n",
    "     \"content\": [{\n",
    "         \"type\":\"text\",\n",
    "         \"text\":f\"\"\"\n",
    "The image shows a location which is represented by a scene graph. A scene graph is a graph with nodes (numbered red circles) representing locations and edges (blue lines) connecting them. \n",
    "A person/ can only move from one node to another if the two nodes are connected by an edge. \n",
    "The scene graph in json file format is also given below, where each node and edge has a unique id, a type, the pixel position of the node in the image (pos). \n",
    "{scene_graph}\n",
    "The type of a node is one among {node_types}. \n",
    "The graph is bidirectional and each edge is also represented with the edge list 'links' in the json given below.  \n",
    "Remember that a node can only be reached from another node if they have an edge between them in the scene graph json.\n",
    "Now answer the following questions below:\n",
    "Is node 0e connected to node 07?\n",
    "Return an answer in JSON format shown below:\"\"\"+\"\"\"\n",
    "{\n",
    "    'ANSWER': True/False,\n",
    "    'REASONING': <Reasoning for answer>\n",
    "}\n",
    "\"\"\"},\n",
    "     {         \n",
    "        \"type\":\"image_url\",\n",
    "        \"image_url\":{\n",
    "            \"url\":f\"data:image/jpeg;base64,{encoded_img}\",\n",
    "            \"detail\":\"high\"\n",
    "        }\n",
    "     }]\n",
    "     },\n",
    "{\"role\": \"assistant\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"\n",
    "{\n",
    "    'ANSWER': False\n",
    "    'REASONING': \"\"To determine if node \"0e\" is connected to node \"07,\" we need to trace the paths in the provided edges.\n",
    "Nodes:\n",
    "\"0e\" at position [80, 660] (type: CORNER)\n",
    "\"07\" at position [28, 318] (type: CORNER)\n",
    "Edges involving \"0e\":\n",
    "{\"type\": \"PASSAGEWAY\", \"source\": \"0e\", \"target\": \"32\"}\n",
    "{\"type\": \"PASSAGEWAY\", \"source\": \"0e\", \"target\": \"cb\"}\n",
    "Edges involving \"07\":\n",
    "{\"type\": \"NARROW PASSAGEWAY\", \"source\": \"11\", \"target\": \"07\"}\n",
    "{\"type\": \"PASSAGEWAY\", \"source\": \"07\", \"target\": \"f7\"}\n",
    "There are no direct or indirect edges connecting \"0e\" to \"07\" through other nodes. Therefore, node \"0e\" is not connected to node \"07\" \"\".\n",
    "}\n",
    "\"\"\"\n",
    "}]},\n",
    "{\"role\": \"user\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"If I walk from node d9 to node aa and take a left turn which node will I reach first?\n",
    "Return an answer in JSON format shown below:\"\"\"+\"\"\"\n",
    "{\n",
    "    'Answer': Node ID,\n",
    "    'Reasoning': <Reasoning for answer>\n",
    "}\"\"\"}]},\n",
    "{\"role\": \"assistant\", \"content\": [{\"type\":\"text\",\n",
    "\"text\":\"\"\"{\n",
    "    \n",
    "'ANSWER': \"47\",\n",
    "\n",
    "'REASONING':\"\n",
    "    To determine which node you will reach first if you walk from node \"d9\" to node \"aa\" and then take a left turn, we need to look at the nodes connected to \"aa\" and identify the left turn from \"aa\".\n",
    "    From the JSON structure:\n",
    "    Node \"aa\" is connected to:\n",
    "    Node \"d9\"\n",
    "    Node \"47\"\n",
    "    Node \"69\"\n",
    "    Node \"99\"\n",
    "    Since you're starting from node \"d9\" and reaching node \"aa\", taking a left turn would typically mean turning towards the next node that is positioned to the left relative to your current direction of movement. Based on the provided positions and assuming you're facing north when reaching \"aa\" from \"d9\":\n",
    "    \"d9\" to \"aa\" positions: (339, 317) to (507, 319) indicates you're moving east.\n",
    "    A left turn from this direction would point you north.\n",
    "    Among the connected nodes to \"aa\", the one positioned north (left turn) is \"47\":\n",
    "    \"47\" position: [503, 148]\n",
    "    Therefore, if you walk from node \"d9\" to node \"aa\" and take a left turn, you will first reach node \"47\".\"\n",
    "    }\"\"\"\n",
    "}]},\n",
    "\n",
    "{\"role\": \"user\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"If I walk from node ba to node 69, which direction am I walking?\n",
    "                              Return an answer in JSON format shown below:\"\"\"+\"\"\"\n",
    "{\n",
    "    'Answer': DIRECTION,\n",
    "    'Reasoning': <Reasoning for answer>\n",
    "}\"\"\"}]},\n",
    "\n",
    "{\"role\": \"assistant\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"\n",
    "                                   \n",
    "{   \n",
    "    'ANSWER': 'NORTH-WEST',\n",
    "    'REASONING': \"\"To determine the direction you are walking when moving from node \"ba\" to node \"69\", we can look at the positions of these nodes in the JSON structure.\n",
    "Node positions:\n",
    "Node \"ba\": [790, 667]\n",
    "Node \"69\": [686, 501]\n",
    "Given these coordinates:\n",
    "Node \"ba\" is located at (790, 667)\n",
    "Node \"69\" is located at (686, 501)\n",
    "Calculating the Direction:\n",
    "The x-coordinate decreases from 790 to 686.\n",
    "The y-coordinate decreases from 667 to 501.\n",
    "Since both the x and y coordinates are decreasing, you are moving in a direction that is generally north-west.\n",
    "Direction Analysis:\n",
    "A decrease in the x-coordinate indicates movement towards the west.\n",
    "A decrease in the y-coordinate indicates movement towards the north.\n",
    "Conclusion:\n",
    "When walking from node \"ba\" to node \"69\", you are walking in a north-west direction.\"\"\n",
    "}\n",
    "\"\"\"}]},\n",
    "{\"role\": \"user\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"If I walk from node 79 to node 99, which direction should I turn to reach node e3?\n",
    "Return an answer in JSON format shown below:\"\"\"+\"\"\"\n",
    "{\n",
    "    'Answer': DIRECTION,\n",
    "    'Reasoning': <Reasoning for answer>\n",
    "}\"\"\"}]},\n",
    "{\"role\": \"assistant\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"\n",
    "{\n",
    "    'Answer': 'left (east)',\n",
    "    'REASONING': \"\"To determine the direction you should turn to reach node \"e3\" after walking from node \"79\" to node \"99,\" we need to look at the relative positions of these nodes.\n",
    "Node positions:\n",
    "Node \"79\": [883, 133]\n",
    "Node \"99\": [893, 315]\n",
    "Node \"e3\": [1124, 309]\n",
    "Movement Analysis:\n",
    "Walking from node \"79\" to node \"99\":\n",
    "\"79\" is located at (883, 133).\n",
    "\"99\" is located at (893, 315).\n",
    "Moving from \"79\" to \"99\" involves primarily moving south (as the y-coordinate increases significantly more than the x-coordinate).\n",
    "Determining the direction to node \"e3\" from node \"99\":\n",
    "\"99\" is located at (893, 315).\n",
    "\"e3\" is located at (1124, 309).\n",
    "Moving from \"99\" to \"e3\" involves primarily moving east (as the x-coordinate increases significantly and the y-coordinate remains almost the same).\n",
    "Conclusion:\n",
    "After walking south from \"79\" to \"99\", you should turn left (east) to reach node \"e3\".\"\"\n",
    "}\n",
    "\n",
    "\"\"\"}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1 = [{\"role\": \"user\", \"content\": [\n",
    "    {\"type\":\"text\",\n",
    "     \"text\":\"\"\"\n",
    "Let's initialize a simulator (like Gazebo) with the world given in the image and described by the json file and try to orchestrate the following human-robot scenario: \n",
    "        \n",
    "Robot is transporting a box from one point to another in the warehouse. While moving along a passageway, it encounters an employee walking in the opposite direction.\n",
    "\n",
    "You must select the trajectories of the humans and the robot to orchestrate this scenario. You must also assign integer group ids to the HUMANS ONLY involved in the scenario according to the \n",
    "following rule:\n",
    "1. All the members of the same group must have the same group id.\n",
    "2. If a human is not involved in a group, they will have a group id of -1.\n",
    "3. If the scenario does not specifically mention a group, then assign -1 to all humans\n",
    "4. All humans involved in the scenario must be assigned a group id.\n",
    "Format your output in json as given below:\n",
    "        {\n",
    "            'REASONING': <Reasoning for Answer>,\n",
    "            'TRAJECTORIES': {\n",
    "                'ROBOT': <...>\n",
    "                'HUMAN 1': <...>,\n",
    "                'HUMAN 2': <...>,\n",
    "                'HUMAN 3': <...>,\n",
    "            },\n",
    "            'GROUP ID':{\n",
    "                'HUMAN 1': ..,\n",
    "                'HUMAN 2': ...,\n",
    "                ...\n",
    "            }\n",
    "        }\"\"\"\n",
    "}]},\n",
    "{\"role\": \"assistant\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"\n",
    "{\n",
    "'REASONING':\"\"To create a scenario where robot is transporting a box from one point to another in the warehouse and encounters an employee walking in the opposite direction along a passageway, we need to identify a suitable passageway and ensure that robot and the employee move towards each other from opposite directions.\n",
    "\n",
    "        ### Scenario Setup:\n",
    "        1. robot starts at one node and moves along a passageway towards a destination node.\n",
    "        2. An employee starts at the destination node and moves along the same passageway towards robot.\n",
    "\n",
    "        ### Suggested Passageway:\n",
    "        We'll use the passageway between nodes \"07\", \"f7\", and \"d9\" again as it is a straightforward path that allows for clear movement in opposite directions.\n",
    "\n",
    "        ### robot's Trajectory:\n",
    "        1. **Start at node \"f7\"** (robot picks up the box here)\n",
    "        2. **Move to node \"07\"** (robot moves along the passageway)\n",
    "\n",
    "        ### Employee's Trajectory:\n",
    "        1. **Start at node \"07\"**\n",
    "        2. **Move to node \"f7\"** (The employee moves along the same passageway towards robot)\n",
    "\n",
    "        ### Detailed Node Sequence:\n",
    "\n",
    "        #### robot's Nodes:\n",
    "        1. f7\n",
    "        2. 07\n",
    "\n",
    "        #### Employee's Nodes:\n",
    "        1. 07\n",
    "        2. f7\n",
    "\n",
    "        ### Path Visualization:\n",
    "        - **robot's Path**: f7 → 07\n",
    "        - **Employee's Path**: 07 → f7\n",
    "\n",
    "        ### Simulator Initialization:\n",
    "        - **robot** starts at node \"f7\" and follows the path f7 → 07.\n",
    "        - **Employee** starts at node \"07\" and follows the path 07 → f7.\n",
    "\n",
    "        Since there is only one human in the scenario and the human is not involved in any groups, the group id for this human is the default -1.\n",
    "\n",
    "        In a simula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_2 = [\n",
    "{\"role\": \"user\", \"content\":[{\"type\":\"text\",\"text\":\"\"\"\n",
    "Now generate trajectories for the following scenario: \n",
    "                             \n",
    "The robot starts at an intersection and needs to transport a box to another intersection on the other side of the warehouse. As it navigates through passageways and intersections, it reaches an open area where two warehouse employees are standing and talking. The open area is halfway through the robot's planned route.\n",
    "        \n",
    "You must select the trajectories of the humans and the robot to orchestrate this scenario. You must also assign integer group ids to the HUMANS ONLY involved in the scenario according to the following rule:\n",
    "1. All the members of the same group must have the same group id.\n",
    "2. If a human is not involved in a group, they will have a group id of -1.\n",
    "3. All humans involved in the scenario must be assigned a group id.\n",
    "Format your output in json as given below:\n",
    "        {\n",
    "           'REASONING': <Reasoning for Answer>,\n",
    "             'TRAJECTORIES': {\n",
    "                'ROBOT': <...>\n",
    "                'HUMAN 1': <...>,\n",
    "                'HUMAN 2': <...>,\n",
    "                'HUMAN 3': <...>,\n",
    "            },\n",
    "            'GROUP IDS':{\n",
    "                'HUMAN 1': ..,\n",
    "                'HUMAN 2': ...,\n",
    "                ...\n",
    "            }\n",
    "}\"\"\"\n",
    "}]},\n",
    "{\"role\": \"assistant\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"\n",
    "{                                   \n",
    "'REASONING':\"\"To create the scenario where a robot starts at an intersection, transports a box to another intersection on the other side of the warehouse, and encounters two employees standing and talking in an open area halfway through its route, we need to carefully plan the robot's trajectory and identify a suitable open area for the employees.\n",
    "\n",
    "    ### Scenario Setup:\n",
    "    1. The robot starts at an intersection.\n",
    "    2. The robot's destination is another intersection on the other side of the warehouse.\n",
    "    3. The robot navigates through passageways and intersections.\n",
    "    4. The robot reaches an open area halfway through its route where two employees are standing and talking.\n",
    "\n",
    "    ### Selected Intersections and Open Area:\n",
    "    - **Start Intersection**: Node \"f7\"\n",
    "    - **Destination Intersection**: Node \"e3\"\n",
    "    - **Open Area (halfway point)**: Node \"69\"\n",
    "\n",
    "    ### Robot's Trajectory:\n",
    "    1. **Start at node \"f7\"**.\n",
    "    2. **Move to node \"d9\"** (intersection).\n",
    "    3. **Move to node \"aa\"** (intersection).\n",
    "    4. **Move to node \"69\"** (open area, halfway point where the employees are).\n",
    "    5. **Move to node \"cf\"** (intersection).\n",
    "    6. **Move to node \"e3\"** (destination intersection).\n",
    "\n",
    "    ### Detailed Node Sequence for the Robot:\n",
    "    1. f7\n",
    "    2. d9\n",
    "    3. aa\n",
    "    4. 69\n",
    "    5. cf\n",
    "    6. e3\n",
    "\n",
    "    ### Positioning the Employees:\n",
    "    - Employees will be standing at node \"69\".\n",
    "    - Since the employees, Human 1 and Human 2 form a group, they are given the same integer group id. Let's assign 1 to both their group ids.\n",
    "    ### Path Visualization:\n",
    "    - **Robot's Path**: f7 → d9 → aa → 69 → cf → e3\n",
    "\n",
    "    ### Simulator Initialization:\n",
    "    1. **Robot**:\n",
    "    - Starts at node \"f7\".\n",
    "    - Follows the path: f7 → d9 → aa → 69 → cf → e3.\n",
    "    2. **Employees**:\n",
    "    - Positioned at node \"69\" in the open area.\n",
    "    - Standing and talking as the robot passes through.\n",
    "\n",
    "    ### Steps to Simulate:\n",
    "    1. Initialize the robot at node \"f7\" with a box.\n",
    "    2. Set the robot to move along the path f7 → d9 → aa → 69 → cf → e3.\n",
    "    3. Place the employees at node \"69\" and set their behavior to standing and talking.\n",
    "    4. Monitor the robot's movement to ensure it encounters the employees at the open area (node \"69\").\n",
    "\n",
    "    This setup ensures that the robot, while navigating from one intersection to another, encounters two employees standing and talking in an open area halfway through its planned route.\"\",\n",
    "\n",
    "'TRAJECTORIES': {\n",
    "        'ROBOT': ['f7','d9','aa','69','cf','e3']\n",
    "        'HUMAN 1': ['69'],\n",
    "        'HUMAN 2':['69']\n",
    "        },\n",
    "'GROUP ID':{\n",
    "    'HUMAN 1': 1,\n",
    "    'HUMAN 2': 1\n",
    "}, \n",
    "}\"\"\"}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scenario_prompt = {\"role\": \"user\", \"content\": [{\"type\":\"text\",\"text\":\"\"\"Now generate trajectories for the following scenario: \n",
    "\n",
    "The robot is tasked with transporting a box through a network of passageways, intersections, and open areas in a small warehouse. While navigating, the robot enters an open area where it encounters a group of 3 warehouse employees standing and conversing\n",
    "\n",
    "You must select the trajectories of the humans and the robot to orchestrate this scenario. You must also assign integer group ids to the HUMANS ONLY involved in the scenario according to the following rule:\n",
    "1. All the members of the same group must have the same group id.\n",
    "2. If a human is not involved in a group, they will have a group id of -1.\n",
    "3. If the scenario does not specifically mention a group, then assign -1 to all humans\n",
    "4. All humans involved in the scenario must be assigned a group id.\n",
    "Format your output in JSON as given below:\n",
    "        {\n",
    "            'REASONING': <Reasoning for Answer>,\n",
    "            'TRAJECTORIES': {\n",
    "                'ROBOT': <...>\n",
    "                'HUMAN 1': <...>,\n",
    "                'HUMAN 2': <...>,\n",
    "                'HUMAN 3': <...>,\n",
    "            },\n",
    "            'GROUP IDS':{\n",
    "                'HUMAN 1': ..,\n",
    "                'HUMAN 2': ...,\n",
    "                ...\n",
    "            }\n",
    "}\"\"\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in scenario_1:\n",
    "    payload.append(msg)\n",
    "for msg in scenario_2:\n",
    "    payload.append(msg)\n",
    "payload.append(new_scenario_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.get_response(\n",
    "    model = MODEL,\n",
    "    messages = payload,\n",
    "    format = \"json_object\",\n",
    "    expected_keys = ['trajectories','reasoning','group ids']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REASONING': \"To create the scenario where a robot is tasked with transporting a box through a network of passageways, intersections, and open areas in a small warehouse, and encounters a group of 3 employees in an open area, we need to carefully plan the robot's trajectory and identify a suitable open area for the employees to be standing and talking. We will also assign a group ID to the humans as they form a group of 3 employees standing and conversing in the open area.\",\n",
       " 'TRAJECTORIES': {'ROBOT': ['f7', 'd9', 'aa', '69', 'cf'],\n",
       "  'HUMAN 1': ['69'],\n",
       "  'HUMAN 2': ['69'],\n",
       "  'HUMAN 3': ['69']},\n",
       " 'GROUP IDS': {'HUMAN 1': 1, 'HUMAN 2': 1, 'HUMAN 3': 1}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.client.chat.completions.create(\n",
    "    model = MODEL,\n",
    "    messages=payload,\n",
    "    response_format={\"type\": \"json_object\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json.loads(response.choices[0].message.content)\n",
    "output_keys = [x.lower() for x in list(output.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('responses/improved_location.json','w') as f:\n",
    "    json.dump(response.choices[0].message.content,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = \"\"\"\n",
    "You made a mistake:\n",
    "48 is not connected to f7. Return it in the same JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload.append(\n",
    "{\n",
    "    \"role\":\"assistant\",\n",
    "    \"content\":[\n",
    "        {\n",
    "            \"type\":\"text\",\n",
    "            \"text\": response.choices[0].message.content\n",
    "        }\n",
    "    ]\n",
    "}    \n",
    ")\n",
    "payload.append({\n",
    "    \"role\": \"user\", \n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\":\"text\",\n",
    "            \"text\": reply +\"\"\"Revise your answer. Return it in the same JSON format.\"\"\"\n",
    "        }\n",
    "                ]\n",
    "              }\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.client.chat.completions.create(\n",
    "    model = MODEL,\n",
    "    messages=payload,\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded for current small warehouse map scene\n",
    "def pix2world(px):\n",
    "    return [-1.0*((px[1]/3.0034965034965) * 0.050000 + -7.000) ,-1*((px[0]/2.6604554865424) * 0.050000 + -10.500000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = json.loads(response.choices[0].message.content)['TRAJECTORIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_trajectories = {}\n",
    "for k,v in trajectories.items():\n",
    "    if 'ROBOT' in k or 'HUMAN' in k:\n",
    "        pixel_trajectories[k] = []\n",
    "        for l in v:\n",
    "            pixel_trajectories[k].append(pix2world(scgraph.graph.nodes[l]['pos']))\n",
    "print(pixel_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pix_pos_passageway ={'HUMAN 1': [(28,318), (31,149)], 'ROBOT': [(31,149), (28,318), (186,320)]}\n",
    "group_open_area = {'HUMAN 1':[(686,501)],'HUMAN 2':[(686,501)],'HUMAN 3':[(686,501)],'ROBOT':[(186,320)]}\n",
    "world_pos = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k,v in group_open_area.items():\n",
    "    world_pos[k] = []\n",
    "    for l in v:\n",
    "        world_pos[k].append(pix2world(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BT Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BTQuery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m btq \u001b[38;5;241m=\u001b[39m \u001b[43mBTQuery\u001b[49m()\n\u001b[1;32m      2\u001b[0m btq_payload \u001b[38;5;241m=\u001b[39m btq\u001b[38;5;241m.\u001b[39mget_full_prompt(\n\u001b[1;32m      3\u001b[0m     behavior \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mIf the robot is visible and in the way, Human 1 requests the robot to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWAIT\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m so they can overtake. If the robot moves aside, Human 1 proceeds to overtake and continues to their goal. If the robot blocks the way or does not respond, Human 1 stands and watches the robot briefly before proceeding to navigate around it \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly if there is enough space.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BTQuery' is not defined"
     ]
    }
   ],
   "source": [
    "btq = BTQuery()\n",
    "btq_payload = btq.get_full_prompt(\n",
    "    behavior = \"\"\"If the robot is visible and in the way, Human 1 requests the robot to 'WAIT' so they can overtake. If the robot moves aside, Human 1 proceeds to overtake and continues to their goal. If the robot blocks the way or does not respond, Human 1 stands and watches the robot briefly before proceeding to navigate around it 'only if there is enough space.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(btq_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.client.chat.completions.create(\n",
    "    model = MODEL,\n",
    "    messages=btq_payload,\n",
    "    response_format={\"type\": \"json_object\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
